# LORA微调

AdamW学习率是3e-4，衰减率为0.01；最佳的SGD（内存占用较少）学习率是0.1，动量为0.9

LoRA超参数微调：增加R值

“r”是LoRA最重要的参数之一，它决定了LoRA矩阵的秩（rank）或维度（dimension），直接影响了模型的复杂度和容量。较高的“r”值意味着更强的表达能力，但可能导致过拟合；较低的“r”值可以减少过拟合，但代价是降低了表达能力。

LoRA超参数调优：更改Alpha

我们在保持LoRA的alpha参数不变的情况下，增加了矩阵秩r，较高的alpha更强调低秩结构或正则化，较低的alpha则减少了其影响，使模型更依赖于原始参数。调整“alpha”有助于在拟合数据和通过正则化防止过拟合之间保持平衡。一般来说，微调LLM时选择的alpha值是秩的两倍（请注意，当使用扩散模型时，情况可能不同）。

当alpha值为秩的两倍（例如，r=256，alpha=512）时，的确产生了最佳结果

```text
r=8:
可训练参数：20277248个
不可训练参数：6738415616个
内存占用：16.42 GB

r=16:
可训练参数：40554496个
不可训练参数：6738415616个
内存占用：16.47 GB
```

我们还可以在查询权重矩阵、投影层、多头注意力模块之间的其他线性层以及输出层启用 LoRA，如果我们在这些附加层上加入 LoRA，那么对于 7B 的 Llama 2 模型，可训练参数的数量将从 4,194,304 增加到 20,277,248，增加五倍。在更多层应用 LoRA，能够显著提高模型性能，但也对内存空间的需求量更高。

# 重要事项

* 模型加速（vLLM）
* 数据集质量很重要（需要包含我们关心的所有任务的数据）
* 需要支持的任务类型比较多的时候（r）值可能需要设置的比较大
* r值和epoch值过大可能会导致训练过拟合
* Alpha值推荐设置成r值的两倍



# 基本概念

* `batch size`：每批训练数据的数量。
* `epoch`：一个完整的迭代过程，即一次完整的训练。
* `batch`：一组训练数据